
<!doctype html>
<html lang="en" class="no-js">
  <head>

      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">

        <meta name="description" content="Uniform Manifold Approximation and Projection">


        <meta name="author" content="Leland McInnes">


        <link rel="canonical" href="https://lmcinnes.github.io/umap/clustering/">


        <link rel="prev" href="../supervised/">


        <link rel="next" href="../inverse_transform/">


      <link rel="icon" href="../doc/logo_large.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">



        <title>Clustering - UMAP</title>



      <link rel="stylesheet" href="../assets/stylesheets/main.6f8fc17f.min.css">


        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">












        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>



    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>






  </head>









    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">


    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">


        <a href="#using-umap-for-clustering" class="md-skip">
          Skip to content
        </a>

    </div>
    <div data-md-component="announce">

    </div>






<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="UMAP" class="md-header__button md-logo" aria-label="UMAP" data-md-component="logo">

  <img src="../doc/logo_large.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">

      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            UMAP
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">

              Clustering

          </span>
        </div>
      </div>
    </div>


        <form class="md-header__option" data-md-component="palette">




    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">

      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>





    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">

      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>


</form>



      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>



      <label class="md-header__button md-icon" for="__search">

        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">

        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>

        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">

        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">

          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>

        <div class="md-search__suggest" data-md-component="search-suggest"></div>

    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>


      <div class="md-header__source">
        <a href="https://github.com/lmcinnes/umap" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    lmcinnes/umap
  </div>
</a>
      </div>

  </nav>

</header>

    <div class="md-container" data-md-component="container">






      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">



              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="UMAP" class="md-nav__button md-logo" aria-label="UMAP" data-md-component="logo">

  <img src="../doc/logo_large.png" alt="logo">

    </a>
    UMAP
  </label>

    <div class="md-nav__source">
      <a href="https://github.com/lmcinnes/umap" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    lmcinnes/umap
  </div>
</a>
    </div>

  <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href=".." class="md-nav__link">


  <span class="md-ellipsis">
    Home
  </span>


      </a>
    </li>













    <li class="md-nav__item md-nav__item--nested">





        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >


          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">


  <span class="md-ellipsis">
    Getting Started
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../basic_usage/" class="md-nav__link">


  <span class="md-ellipsis">
    Installation
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../how_umap_works/" class="md-nav__link">


  <span class="md-ellipsis">
    How UMAP Works
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../reproducibility/" class="md-nav__link">


  <span class="md-ellipsis">
    Reproducibility
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>















    <li class="md-nav__item md-nav__item--active md-nav__item--nested">



        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>


          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">


  <span class="md-ellipsis">
    User Guide
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../basic_usage/" class="md-nav__link">


  <span class="md-ellipsis">
    Installation
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../parameters/" class="md-nav__link">


  <span class="md-ellipsis">
    Parameters
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../supervised/" class="md-nav__link">


  <span class="md-ellipsis">
    Supervised Dimensionality Reduction
  </span>


      </a>
    </li>












    <li class="md-nav__item md-nav__item--active">

      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">





        <label class="md-nav__link md-nav__link--active" for="__toc">


  <span class="md-ellipsis">
    Clustering
  </span>


          <span class="md-nav__icon md-icon"></span>
        </label>

      <a href="./" class="md-nav__link md-nav__link--active">


  <span class="md-ellipsis">
    Clustering
  </span>


      </a>



<nav class="md-nav md-nav--secondary" aria-label="Table of contents">






    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>

        <li class="md-nav__item">
  <a href="#traditional-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional clustering
    </span>
  </a>

</li>

        <li class="md-nav__item">
  <a href="#umap-enhanced-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      UMAP enhanced clustering
    </span>
  </a>

</li>

    </ul>

</nav>

    </li>










    <li class="md-nav__item">
      <a href="../inverse_transform/" class="md-nav__link">


  <span class="md-ellipsis">
    Inverse Transform
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../sparse/" class="md-nav__link">


  <span class="md-ellipsis">
    Sparse Data
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>













    <li class="md-nav__item md-nav__item--nested">





        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >


          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">


  <span class="md-ellipsis">
    Advanced Topics
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Advanced Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../composing_models/" class="md-nav__link">


  <span class="md-ellipsis">
    Composing Models
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../aligned_umap_basic_usage/" class="md-nav__link">


  <span class="md-ellipsis">
    Aligned UMAP
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../aligned_umap_politics_demo/" class="md-nav__link">


  <span class="md-ellipsis">
    Aligned UMAP - Politics Demo
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../embedding_space/" class="md-nav__link">


  <span class="md-ellipsis">
    Embedding Space
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../exploratory_analysis/" class="md-nav__link">


  <span class="md-ellipsis">
    Exploratory Analysis
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>













    <li class="md-nav__item md-nav__item--nested">





        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >


          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">


  <span class="md-ellipsis">
    Variants and Extensions
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Variants and Extensions
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../densmap_demo/" class="md-nav__link">


  <span class="md-ellipsis">
    densMAP
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../parametric_umap/" class="md-nav__link">


  <span class="md-ellipsis">
    Parametric UMAP
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../mutual_nn_umap/" class="md-nav__link">


  <span class="md-ellipsis">
    Mutual Nearest Neighbors UMAP
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../transform/" class="md-nav__link">


  <span class="md-ellipsis">
    Transform & Inference
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../transform_landmarked_pumap/" class="md-nav__link">


  <span class="md-ellipsis">
    Landmarked Parametric UMAP
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>













    <li class="md-nav__item md-nav__item--nested">





        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >


          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">


  <span class="md-ellipsis">
    Visualization and Interactive
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Visualization and Interactive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../plotting/" class="md-nav__link">


  <span class="md-ellipsis">
    Plotting
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../interactive_viz/" class="md-nav__link">


  <span class="md-ellipsis">
    Interactive Visualization
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../outliers/" class="md-nav__link">


  <span class="md-ellipsis">
    Outlier Detection
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../document_embedding/" class="md-nav__link">


  <span class="md-ellipsis">
    Document Embedding
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../nomic_atlas_umap_of_text_embeddings/" class="md-nav__link">


  <span class="md-ellipsis">
    Nomic Atlas - Text Embeddings
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../nomic_atlas_visualizing_mnist_training_dynamics/" class="md-nav__link">


  <span class="md-ellipsis">
    Nomic Atlas - MNIST Training
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>













    <li class="md-nav__item md-nav__item--nested">





        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >


          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">


  <span class="md-ellipsis">
    Performance & Optimization
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Performance & Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../performance/" class="md-nav__link">


  <span class="md-ellipsis">
    Performance
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../benchmarking/" class="md-nav__link">


  <span class="md-ellipsis">
    Benchmarking
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../precomputed_k-nn/" class="md-nav__link">


  <span class="md-ellipsis">
    Precomputed k-NN
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>













    <li class="md-nav__item md-nav__item--nested">





        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >


          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">


  <span class="md-ellipsis">
    Reference & Support
  </span>


            <span class="md-nav__icon md-icon"></span>
          </label>

        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Reference & Support
          </label>
          <ul class="md-nav__list" data-md-scrollfix>







    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">


  <span class="md-ellipsis">
    API Reference
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">


  <span class="md-ellipsis">
    FAQ
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../scientific_papers/" class="md-nav__link">


  <span class="md-ellipsis">
    Scientific Papers
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../release_notes/" class="md-nav__link">


  <span class="md-ellipsis">
    Release Notes
  </span>


      </a>
    </li>










    <li class="md-nav__item">
      <a href="../development_roadmap/" class="md-nav__link">


  <span class="md-ellipsis">
    Development Roadmap
  </span>


      </a>
    </li>




          </ul>
        </nav>

    </li>



  </ul>
</nav>
                  </div>
                </div>
              </div>



              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">


<nav class="md-nav md-nav--secondary" aria-label="Table of contents">






    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>

        <li class="md-nav__item">
  <a href="#traditional-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional clustering
    </span>
  </a>

</li>

        <li class="md-nav__item">
  <a href="#umap-enhanced-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      UMAP enhanced clustering
    </span>
  </a>

</li>

    </ul>

</nav>
                  </div>
                </div>
              </div>



            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">







<h1 id="using-umap-for-clustering">Using UMAP for Clustering<a class="headerlink" href="#using-umap-for-clustering" title="Permanent link">&para;</a></h1>
<p>UMAP can be used as an effective preprocessing step to boost the
performance of density based clustering. This is somewhat controversial,
and should be attempted with care. For a good discussion of some of the
issues involved in this, please see the various answers <code>in this
stackoverflow
thread &lt;https://stats.stackexchange.com/questions/263539/clustering-on-the-output-of-t-sne&gt;</code>__
on clustering the results of t-SNE. Many of the points of concern raised
there are salient for clustering the results of UMAP. The most notable
is that UMAP, like t-SNE, does not completely preserve density. UMAP,
like t-SNE, can also create false tears in clusters, resulting in a
finer clustering than is necessarily present in
the data. Despite these concerns there are still valid reasons to use
UMAP as a preprocessing step for clustering. As with any clustering
approach one will want to do some exploration and evaluation of the
clusters that come out to try to validate them if possible.</p>
<p>With all of that said, let's work through an example to demonstrate the
difficulties that can face clustering approaches and how UMAP can
provide a powerful tool to help overcome them.</p>
<p>First we'll need a selection of libraries loaded up. Obviously we'll
need data, and we can use sklearn's <code>fetch_openml</code> to get it. We'll
also need the usual tools of numpy, and plotting. Next we'll need umap,
and some clustering options. Finally, since we'll be working with
labeled data, we can make use of strong cluster evaluation metrics
<code>Adjusted Rand
Index &lt;https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index&gt;</code>__
and <code>Adjusted Mutual
Information &lt;https://en.wikipedia.org/wiki/Adjusted_mutual_information&gt;</code>__.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># Dimension reduction and clustering libraries</span>
<span class="kn">import</span> <span class="nn">umap</span>
<span class="kn">import</span> <span class="nn">hdbscan</span>
<span class="kn">import</span> <span class="nn">sklearn.cluster</span> <span class="k">as</span> <span class="nn">cluster</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span><span class="p">,</span> <span class="n">adjusted_mutual_info_score</span>
</code></pre></div>
<p>Now let's set up the plotting and grab the data we'll be using -- in
this case the MNIST handwritten digits dataset. MNIST consists of 28x28
pixel grayscale images of handwritten digits (0 through 9). These can be
unraveled such that each digit is described by a 784 dimensional vector
(the gray scale value of each pixel in the image). Ideally we would like
the clustering to recover the digit structure.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mnist</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div>
<p>For visualization purposes we can reduce the data to 2-dimensions using
UMAP. When we cluster the data in high dimensions we can visualize the
result of that clustering. First, however, we'll view the data colored
by the digit that each data point represents -- we'll use a different
color for each digit. This will help frame what follows.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">standard_embedding</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">standard_embedding</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">standard_embedding</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Spectral&#39;</span><span class="p">);</span>
</code></pre></div>
<p><img alt="Image" src="images/clustering_6_1.png" /></p>
<h3 id="traditional-clustering">Traditional clustering<a class="headerlink" href="#traditional-clustering" title="Permanent link">&para;</a></h3>
<p>Now we would like to cluster the data. As a first attempt let's try the
traditional approach: K-Means. In this case we can solve one of the hard
problems for K-Means clustering -- choosing the right k value, giving
the number of clusters we are looking for. In this case we know the
answer is exactly 10. We will use sklearns K-Means implementation
looking for 10 clusters in the original 784 dimensional data.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">kmeans_labels</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>
<p>And how did the clustering do? We can look at the results by coloring
out UMAP embedded data by cluster membership.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">standard_embedding</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">standard_embedding</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">kmeans_labels</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Spectral&#39;</span><span class="p">);</span>
</code></pre></div>
<p><img alt="Image" src="images/clustering_10_1.png" /></p>
<p>This is not really the result we were looking for (though it does expose
interesting properties of how K-Means chooses clusters in high
dimensional space, and how UMAP unwraps manifolds by finding manifold
boundaries). While K-Means gets some cases correct, such as the two clusters
on the right side which are mostly correct, most of the rest of the data looks
somewhat arbitrarily carved up among the remaining clusters. We can put
this impression to the test by evaluating the adjusted Rand score and
adjusted mutual information for this clustering as compared with the
true labels.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="p">(</span>
    <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">kmeans_labels</span><span class="p">),</span>
    <span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">kmeans_labels</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>(0.36675295135972552, 0.49614118437750965)
</code></pre></div>
<p>As might be expected, we have not done a particularly good job -- both
scores take values in the range 0 to 1, with 0 representing a bad
(essentially random) clustering and 1 representing perfectly recovering
the true labels. K-Means definitely was not random, but it was also
quite a long way from perfectly recovering the true labels. Part of the
problem is the way K-Means works, based on centroids with an assumption
of largely spherical clusters -- this is responsible for some of the
sharp divides that K-Means puts across digit classes. We can potentially
improve on this by using a smarter density based algorithm. In this case
we've chosen to try HDBSCAN, which we believe to be among the most
advanced density based techniques. For the sake of performance we'll
reduce the dimensionality of the data down to 50 dimensions via PCA
(this recovers most of the variance), since HDBSCAN scales somewhat
poorly with the dimensionality of the data it will work on.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">lowd_mnist</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">hdbscan_labels</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_cluster_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">lowd_mnist</span><span class="p">)</span>
</code></pre></div>
<p>We can now inspect the results. Before we do, however, it should be
noted that one of the features of HDBSCAN is that it can refuse to
cluster some points and classify them as "noise". To visualize this
aspect we will color points that were classified as noise gray, and then
color the remaining points according to the cluster membership.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">clustered</span> <span class="o">=</span> <span class="p">(</span><span class="n">hdbscan_labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">standard_embedding</span><span class="p">[</span><span class="o">~</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">standard_embedding</span><span class="p">[</span><span class="o">~</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">standard_embedding</span><span class="p">[</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">standard_embedding</span><span class="p">[</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">hdbscan_labels</span><span class="p">[</span><span class="n">clustered</span><span class="p">],</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Spectral&#39;</span><span class="p">);</span>
</code></pre></div>
<p><img alt="Image" src="images/clustering_16_1.png" /></p>
<p>This looks somewhat underwhelming. It meets HDBSCAN's approach of "not
being wrong" by simply refusing to classify the majority of the data.
The result is a clustering that almost certainly fails to recover all
the labels. We can verify this by looking at the clustering validation
scores.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="p">(</span>
    <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">hdbscan_labels</span><span class="p">),</span>
    <span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">hdbscan_labels</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>(0.053830107882840102, 0.19756104096566332)
</code></pre></div>
<p>These scores are far worse than K-Means! Partially this is due to the
fact that these scores assume that the noise points are simply an extra
cluster. We can instead only look at the subset of the data that HDBSCAN
was actually confident enough to assign to clusters -- a simple
sub-selection will let us recompute the scores for only that data.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">clustered</span> <span class="o">=</span> <span class="p">(</span><span class="n">hdbscan_labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">(</span>
    <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">clustered</span><span class="p">],</span> <span class="n">hdbscan_labels</span><span class="p">[</span><span class="n">clustered</span><span class="p">]),</span>
    <span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">clustered</span><span class="p">],</span> <span class="n">hdbscan_labels</span><span class="p">[</span><span class="n">clustered</span><span class="p">])</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>(0.99843407988303912, 0.99405521087764015)
</code></pre></div>
<p>And here we see that where HDBSCAN was willing to cluster it got things
almost entirely correct. This is what it was designed to do -- be right
for what it can, and defer on anything that it couldn't have sufficient
confidence in. Of course the catch here is that it deferred clustering a
lot of the data. How much of the data did HDBSCAN actually assign to
clusters? We can compute that easily enough.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">clustered</span><span class="p">)</span> <span class="o">/</span> <span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>0.17081428571428572
</code></pre></div>
<p>It seems that less than 18% of the data was clustered. While HDBSCAN did
a great job on the data it could cluster it did a poor job of actually
managing to cluster the data. The problem here is that, as a density
based clustering algorithm, HDBSCAN tends to suffer from the curse of
dimensionality: high dimensional data requires more observed samples to
produce much density. If we could reduce the dimensionality of the data
more we would make the density more evident and make it far easier for
HDBSCAN to cluster the data. The problem is that trying to use PCA to do
this is going to become problematic. While reducing the 50 dimensions
still explained a lot of the variance of the data, reducing further is
going to quickly do a lot worse. This is due to the linear nature of
PCA. What we need is strong manifold learning, and this is where UMAP
can come into play.</p>
<h3 id="umap-enhanced-clustering">UMAP enhanced clustering<a class="headerlink" href="#umap-enhanced-clustering" title="Permanent link">&para;</a></h3>
<p>Our goal is to make use of UMAP to perform non-linear manifold aware
dimension reduction so we can get the dataset down to a number of
dimensions small enough for a density based clustering algorithm to make
progress. One advantage of UMAP for this is that it doesn't require you
to reduce to only two dimensions -- you can reduce to 10 dimensions
instead since the goal is to cluster, not visualize, and the performance
cost with UMAP is minimal. As it happens MNIST is such a simple dataset
that we really can push it all the way down to only two dimensions, but
in general you should explore different embedding dimension options.</p>
<p>The next thing to be aware of is that when using UMAP for dimension
reduction you will want to select different parameters than if you were
using it for visualization. First of all we will want a larger
<code>n_neighbors</code> value -- small values will focus more on very local
structure and are more prone to producing fine grained cluster structure
that may be more a result of patterns of noise in the data than actual
clusters. In this case we'll double it from the default 15 up to 30.
Second it is beneficial to set <code>min_dist</code> to a very low value. Since
we actually want to pack points together densely (density is what we
want after all) a low value will help, as well as making cleaner
separations between clusters. In this case we will simply set
<code>min_dist</code> to be 0.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">clusterable_embedding</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>
<p>We can visualize the results of this so see how it compares with more
visualization attuned parameters:</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">clusterable_embedding</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">clusterable_embedding</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Spectral&#39;</span><span class="p">);</span>
</code></pre></div>
<p><img alt="Image" src="images/clustering_27_1.png" /></p>
<p>As you can see we still have the general global structure, but we are
packing points together more tightly within clusters, and consequently
we can see larger gaps between the clusters. Ultimately this embedding
was for clustering purposes only, and we will go back to the original
embedding for visualization purposes from here on out.</p>
<p>The next step is to cluster this data. We'll use HDBSCAN again, with the
same parameter setting as before.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">labels</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span>
    <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">min_cluster_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">clusterable_embedding</span><span class="p">)</span>
</code></pre></div>
<p>And now we can visualize the results, just as before.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">clustered</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">standard_embedding</span><span class="p">[</span><span class="o">~</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">standard_embedding</span><span class="p">[</span><span class="o">~</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">standard_embedding</span><span class="p">[</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">standard_embedding</span><span class="p">[</span><span class="n">clustered</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">clustered</span><span class="p">],</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Spectral&#39;</span><span class="p">);</span>
</code></pre></div>
<p><img alt="Image" src="images/clustering_31_1.png" /></p>
<p>We can see that we have done a much better job of finding clusters
rather than merely assigning the majority of data as noise. This is
because we no longer have to try to cope with the relative lack
of density in 50 dimensional space and now HDBSCAN can more cleanly
discern the clusters.</p>
<p>We can also make a quantitative assessment by using the clustering
quality measures as before.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>(0.9239306564265013, 0.90302671641133736)
</code></pre></div>
<p>Where before HDBSCAN performed very poorly, we now have scores of 0.9 or
better. This is because we actually clustered far more of the data. As
before we can also look at how the clustering did on just the data that
HDBSCAN was confident in clustering.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">clustered</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">(</span>
    <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">clustered</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">clustered</span><span class="p">]),</span>
    <span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">clustered</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">clustered</span><span class="p">])</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>(0.93240371696811541, 0.91912906363537572)
</code></pre></div>
<p>This is a little worse than the original HDBSCAN, but it is unsurprising
that you are going to be wrong more often if you make more predictions.
The question is how much more of the data is HDBSCAN actually
clustering? Previously we were clustering only 17% of the data.</p>
<div class="highlight"><span class="filename">Python</span><pre><span></span><code><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">clustered</span><span class="p">)</span> <span class="o">/</span> <span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><span class="filename">Text Only</span><pre><span></span><code>0.99164285714285716
</code></pre></div>
<p>Now we are clustering over 99% of the data! And our results in terms of
adjusted Rand score and adjusted mutual information are in line with the
current state of the art techniques using convolutional autoencoder
techniques. That's not bad for an approach that is simply viewing the
data as arbitrary 784 dimensional vectors.</p>
<p>Hopefully this has outlined how UMAP can be beneficial for clustering.
As with all things care must be taken, but clearly UMAP can provide
significantly better clustering results when used judiciously.</p>













              </article>
            </div>


<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>

          <button type="button" class="md-top md-icon" data-md-component="top" hidden>

  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>

      </main>

        <footer class="md-footer">

  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">

    <div class="md-copyright__highlight">
      Copyright &copy; 2017-2024 Leland McInnes
    </div>


    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>

</div>

    </div>
  </div>
</footer>

    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>


    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.expand", "navigation.top", "content.code.copy", "content.tooltips", "search.suggest", "search.highlight"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>


      <script src="../assets/javascripts/bundle.83f73b43.min.js"></script>


  </body>
</html>
